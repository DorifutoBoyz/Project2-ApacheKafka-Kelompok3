{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Sentiment Analysis Dataset reddit-depression-dataset Dengan Menggunakan PySpark"]},{"cell_type":"markdown","metadata":{},"source":["## Setup Requirement"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-12T03:12:27.313139Z","iopub.status.busy":"2024-11-12T03:12:27.312113Z","iopub.status.idle":"2024-11-12T03:13:58.123783Z","shell.execute_reply":"2024-11-12T03:13:58.122140Z","shell.execute_reply.started":"2024-11-12T03:12:27.313092Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyspark\n","  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840629 sha256=30f3a99b00177475ee2c8e89a736f51c6ef16af50c4c1194f88a6066fdfe07f1\n","  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.3\n","Collecting findspark\n","  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n","Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n","Installing collected packages: findspark\n","Successfully installed findspark-2.0.1\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\n","Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.12.2)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from seaborn) (2.2.3)\n","Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2024.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"]},{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","24/11/12 03:13:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["!pip install pyspark\n","!pip install findspark\n","!pip install matplotlib seaborn scikit-learn\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n","from pyspark.ml.feature import StringIndexer\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","\n","spark = SparkSession.builder \\\n","    .appName('dt_rf_gbt') \\\n","    .config(\"spark.executor.memory\", \"4g\") \\\n","    .config(\"spark.driver.memory\", \"4g\") \\\n","    .config(\"spark.executor.memoryOverhead\", \"1g\") \\\n","    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\") \\\n","    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n","    .getOrCreate()\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T03:13:58.127970Z","iopub.status.busy":"2024-11-12T03:13:58.126953Z","iopub.status.idle":"2024-11-12T03:13:58.134026Z","shell.execute_reply":"2024-11-12T03:13:58.132834Z","shell.execute_reply.started":"2024-11-12T03:13:58.127906Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["## Load Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T03:13:58.136138Z","iopub.status.busy":"2024-11-12T03:13:58.135643Z","iopub.status.idle":"2024-11-12T03:14:56.596121Z","shell.execute_reply":"2024-11-12T03:14:56.594944Z","shell.execute_reply.started":"2024-11-12T03:13:58.136081Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/2565652463.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df_pandas = pd.read_csv(file_path)\n"]},{"name":"stdout","output_type":"stream","text":["Size Dataset: 1921.14 MB.\n","Jumlah data setelah penyeimbangan - Label 0: 480411, Label 1: 480411\n","Size Dataset setelah dipotong dan seimbang: 452.18 MB.\n","Jumlah data pada sampel 100MB - Label 0: 216280, Label 1: 216018\n"]}],"source":["import pandas as pd\n","import os\n","\n","# Load dataset\n","file_path = \"/kaggle/input/reddit-depression-dataset/reddit_depression_dataset.csv\"\n","df_pandas = pd.read_csv(file_path)\n","\n","file_size = os.path.getsize(file_path)\n","memory_usage_bytes = df_pandas.memory_usage(deep=True).sum()\n","memory_usage_mb = memory_usage_bytes / (1024 * 1024)\n","print(f\"Size Dataset: {memory_usage_mb:.2f} MB.\")\n","\n","# Pisahkan data berdasarkan label\n","df_label_0 = df_pandas[df_pandas['label'] == 0]\n","df_label_1 = df_pandas[df_pandas['label'] == 1]\n","\n","# Tentukan jumlah minimum dari kedua label untuk membuat dataset seimbang\n","min_count = min(len(df_label_0), len(df_label_1))\n","\n","# Lakukan undersampling pada label mayoritas\n","df_label_0_balanced = df_label_0.sample(n=min_count, random_state=42)\n","df_label_1_balanced = df_label_1.sample(n=min_count, random_state=42)\n","\n","# Gabungkan kembali data yang seimbang\n","df_balanced = pd.concat([df_label_0_balanced, df_label_1_balanced])\n","\n","# Tampilkan jumlah data untuk setiap label setelah penyeimbangan\n","count_label_0 = df_balanced[df_balanced['label'] == 0].shape[0]\n","count_label_1 = df_balanced[df_balanced['label'] == 1].shape[0]\n","print(f\"Jumlah data setelah penyeimbangan - Label 0: {count_label_0}, Label 1: {count_label_1}\")\n","\n","# Hitung ukuran dataset dan tentukan berapa baris yang diperlukan untuk mencapai 100 MB\n","file_size = os.path.getsize(file_path)\n","target_size = 500 * 1024 * 1024  # 100 MB\n","total_rows = len(df_balanced)\n","rows_for_100mb = int(total_rows * (target_size / file_size))\n","\n","# Ambil sampel sebesar 100 MB dari data yang sudah seimbang\n","df_pandas_sampled = df_balanced.sample(n=rows_for_100mb, random_state=42)\n","\n","# Cek ukuran dataset setelah disampling\n","memory_usage_bytes = df_pandas_sampled.memory_usage(deep=True).sum()\n","memory_usage_mb = memory_usage_bytes / (1024 * 1024)\n","print(f\"Size Dataset setelah dipotong dan seimbang: {memory_usage_mb:.2f} MB.\")\n","\n","# Tampilkan jumlah data dengan label 0 dan 1 pada sampel akhir\n","count_label_0_sampled = df_pandas_sampled[df_pandas_sampled['label'] == 0].shape[0]\n","count_label_1_sampled = df_pandas_sampled[df_pandas_sampled['label'] == 1].shape[0]\n","print(f\"Jumlah data pada sampel 100MB - Label 0: {count_label_0_sampled}, Label 1: {count_label_1_sampled}\")\n","\n","output_path = \"/kaggle/working/reddit_depression_dataset_sampled.csv\"\n","df_pandas_sampled.to_csv(output_path, index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Analysis Dataset"]},{"cell_type":"markdown","metadata":{},"source":["### Info Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:21:14.410330Z","iopub.status.busy":"2024-11-12T01:21:14.409840Z","iopub.status.idle":"2024-11-12T01:21:14.436415Z","shell.execute_reply":"2024-11-12T01:21:14.434485Z","shell.execute_reply.started":"2024-11-12T01:21:14.410281Z"},"trusted":true},"outputs":[],"source":["df_pandas.info()"]},{"cell_type":"markdown","metadata":{},"source":["### Info Data Kosong"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:21:14.450203Z","iopub.status.busy":"2024-11-12T01:21:14.449698Z","iopub.status.idle":"2024-11-12T01:21:15.744500Z","shell.execute_reply":"2024-11-12T01:21:15.743093Z","shell.execute_reply.started":"2024-11-12T01:21:14.450152Z"},"trusted":true},"outputs":[],"source":["df_pandas.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["### Visualisasi Distribusi Label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:21:15.747169Z","iopub.status.busy":"2024-11-12T01:21:15.746493Z","iopub.status.idle":"2024-11-12T01:21:16.135459Z","shell.execute_reply":"2024-11-12T01:21:16.134120Z","shell.execute_reply.started":"2024-11-12T01:21:15.747120Z"},"trusted":true},"outputs":[],"source":["sns.countplot(x='label', data=df_pandas_sampled)\n","plt.title('Distribusi Label')\n","plt.xlabel('Label')\n","plt.ylabel('Jumlah')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Pre-Processing"]},{"cell_type":"markdown","metadata":{},"source":["## Drop data yang kosong"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:21:16.138877Z","iopub.status.busy":"2024-11-12T01:21:16.137868Z","iopub.status.idle":"2024-11-12T01:21:49.717444Z","shell.execute_reply":"2024-11-12T01:21:49.716077Z","shell.execute_reply.started":"2024-11-12T01:21:16.138828Z"},"trusted":true},"outputs":[],"source":["df = spark.createDataFrame(df_pandas_sampled)\n","\n","df_clean = df.dropna(subset=['label', 'title', 'body'])\n","df_clean = df.dropna(subset=['upvotes', 'num_comments'])"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenisasi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:21:49.719613Z","iopub.status.busy":"2024-11-12T01:21:49.718931Z","iopub.status.idle":"2024-11-12T01:21:49.952891Z","shell.execute_reply":"2024-11-12T01:21:49.951590Z","shell.execute_reply.started":"2024-11-12T01:21:49.719555Z"},"trusted":true},"outputs":[],"source":["df_clean = df_clean.withColumn('text', F.concat(F.col('title'), F.lit(' '), F.col('body')))\n","\n","tokenizer = Tokenizer(inputCol='text', outputCol='tokens')\n","df_tokenized = tokenizer.transform(df_clean)"]},{"cell_type":"markdown","metadata":{},"source":["## Visualisasi Distribusi Panjang Teks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:21:49.954777Z","iopub.status.busy":"2024-11-12T01:21:49.954302Z","iopub.status.idle":"2024-11-12T01:22:17.678822Z","shell.execute_reply":"2024-11-12T01:22:17.677058Z","shell.execute_reply.started":"2024-11-12T01:21:49.954725Z"},"trusted":true},"outputs":[],"source":["df_pandas_clean = df_clean.toPandas()\n","df_pandas_clean['text_length'] = df_pandas_clean['text'].apply(lambda x: len(x.split()))\n","\n","plt.figure(figsize=(10,6))\n","sns.histplot(df_pandas_clean['text_length'], bins=30, kde=True)\n","plt.title('Distribusi Panjang Teks')\n","plt.xlabel('Jumlah Kata dalam Teks')\n","plt.ylabel('Frekuensi')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Hapus StopWords"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:22:17.705463Z","iopub.status.busy":"2024-11-12T01:22:17.694541Z","iopub.status.idle":"2024-11-12T01:22:18.074152Z","shell.execute_reply":"2024-11-12T01:22:18.072711Z","shell.execute_reply.started":"2024-11-12T01:22:17.705389Z"},"trusted":true},"outputs":[],"source":["remover = StopWordsRemover(inputCol='tokens', outputCol='filtered_tokens')\n","df_no_stopwords = remover.transform(df_tokenized)"]},{"cell_type":"markdown","metadata":{},"source":["## Vektorisasi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:22:18.076568Z","iopub.status.busy":"2024-11-12T01:22:18.076004Z","iopub.status.idle":"2024-11-12T01:22:47.694042Z","shell.execute_reply":"2024-11-12T01:22:47.692737Z","shell.execute_reply.started":"2024-11-12T01:22:18.076518Z"},"trusted":true},"outputs":[],"source":["hashing_tf = HashingTF(inputCol='filtered_tokens', outputCol='raw_features', numFeatures=10000)\n","df_featurized = hashing_tf.transform(df_no_stopwords)\n","\n","idf = IDF(inputCol='raw_features', outputCol='features')\n","idf_model = idf.fit(df_featurized)\n","df = idf_model.transform(df_featurized)\n","\n","df.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Hapus Column yang tidak perlu"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:22:47.696257Z","iopub.status.busy":"2024-11-12T01:22:47.695800Z","iopub.status.idle":"2024-11-12T01:22:47.715886Z","shell.execute_reply":"2024-11-12T01:22:47.714751Z","shell.execute_reply.started":"2024-11-12T01:22:47.696209Z"},"trusted":true},"outputs":[],"source":["df = df.drop(\"Unnamed: 0\", \"subreddit\", \"title\", \"body\", \"tokens\", \"filtered_tokens\", \"text\", \"raw_features\", \"created_utc\")\n","df.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["## Cek Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:22:47.717898Z","iopub.status.busy":"2024-11-12T01:22:47.717395Z","iopub.status.idle":"2024-11-12T01:23:05.018285Z","shell.execute_reply":"2024-11-12T01:23:05.017004Z","shell.execute_reply.started":"2024-11-12T01:22:47.717850Z"},"trusted":true},"outputs":[],"source":["from pyspark.sql.functions import col, sum\n","\n","# Count null or NaN values in each column\n","df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:23:05.025731Z","iopub.status.busy":"2024-11-12T01:23:05.024065Z","iopub.status.idle":"2024-11-12T01:23:09.212753Z","shell.execute_reply":"2024-11-12T01:23:09.211792Z","shell.execute_reply.started":"2024-11-12T01:23:05.025675Z"},"trusted":true},"outputs":[],"source":["df.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Processing"]},{"cell_type":"markdown","metadata":{},"source":["## Splitting"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:23:09.214718Z","iopub.status.busy":"2024-11-12T01:23:09.213989Z","iopub.status.idle":"2024-11-12T01:23:09.415144Z","shell.execute_reply":"2024-11-12T01:23:09.413929Z","shell.execute_reply.started":"2024-11-12T01:23:09.214664Z"},"trusted":true},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","\n","assembler = VectorAssembler(inputCols=['upvotes', 'num_comments', 'features'], outputCol='final_features')\n","\n","df_combined = assembler.transform(df)\n","\n","df_combined = df_combined.select('final_features', 'label')\n","\n","train_data, test_data = df_combined.randomSplit([0.8, 0.2], seed=42)"]},{"cell_type":"markdown","metadata":{},"source":["## Random Forest"]},{"cell_type":"markdown","metadata":{},"source":["### Import Modul"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:23:09.416904Z","iopub.status.busy":"2024-11-12T01:23:09.416446Z","iopub.status.idle":"2024-11-12T01:23:09.423155Z","shell.execute_reply":"2024-11-12T01:23:09.421968Z","shell.execute_reply.started":"2024-11-12T01:23:09.416855Z"},"trusted":true},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator"]},{"cell_type":"markdown","metadata":{},"source":["### Jalankan Algo"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:23:09.425719Z","iopub.status.busy":"2024-11-12T01:23:09.424979Z","iopub.status.idle":"2024-11-12T01:27:17.839923Z","shell.execute_reply":"2024-11-12T01:27:17.838466Z","shell.execute_reply.started":"2024-11-12T01:23:09.425668Z"},"trusted":true},"outputs":[],"source":["rf_classifier = RandomForestClassifier(labelCol='label', featuresCol='final_features', numTrees=100)\n","\n","rf_model = rf_classifier.fit(train_data)\n","\n","predictions = rf_model.transform(test_data)\n","\n","predictions.show(10)\n","\n","evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n","accuracy = evaluator.evaluate(predictions)\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n","\n","f1_evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='f1')\n","f1_score = f1_evaluator.evaluate(predictions)\n","print(f\"F1-Score: {f1_score:.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Visulisasi Confusion Matrix "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:27:17.842399Z","iopub.status.busy":"2024-11-12T01:27:17.841909Z","iopub.status.idle":"2024-11-12T01:27:38.568649Z","shell.execute_reply":"2024-11-12T01:27:38.567473Z","shell.execute_reply.started":"2024-11-12T01:27:17.842349Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","# Mengambil prediksi dan label sebenarnya dari PySpark ke Pandas\n","predictions_pd = predictions.select('label', 'prediction').toPandas()\n","\n","# Membuat confusion matrix\n","cm = confusion_matrix(predictions_pd['label'], predictions_pd['prediction'])\n","\n","# Visualisasi confusion matrix\n","plt.figure(figsize=(8,6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Prediksi')\n","plt.ylabel('Label Sebenarnya')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Visualisasi ROC Curve and AUC"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:27:38.570710Z","iopub.status.busy":"2024-11-12T01:27:38.570231Z","iopub.status.idle":"2024-11-12T01:28:00.847003Z","shell.execute_reply":"2024-11-12T01:28:00.845827Z","shell.execute_reply.started":"2024-11-12T01:27:38.570662Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","\n","# Mengambil probabilitas prediksi dari PySpark ke Pandas\n","y_true = predictions_pd['label']\n","y_scores = predictions.select('probability').toPandas()['probability'].apply(lambda x: x[1])\n","\n","# Menghitung ROC Curve dan AUC\n","fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","roc_auc = auc(fpr, tpr)\n","\n","# Visualisasi ROC Curve\n","plt.figure(figsize=(8,6))\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Save Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:28:00.849028Z","iopub.status.busy":"2024-11-12T01:28:00.848621Z","iopub.status.idle":"2024-11-12T01:28:01.110455Z","shell.execute_reply":"2024-11-12T01:28:01.108189Z","shell.execute_reply.started":"2024-11-12T01:28:00.848970Z"},"trusted":true},"outputs":[],"source":["rf_model_path = \"/kaggle/working/random_forest_model\"\n","rf_model.save(rf_model_path)\n","\n","print(f\"Random Forest model saved at {rf_model_path}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Decision Tree"]},{"cell_type":"markdown","metadata":{},"source":["### Import Modul"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:29:07.859709Z","iopub.status.busy":"2024-11-12T01:29:07.859151Z","iopub.status.idle":"2024-11-12T01:29:07.865336Z","shell.execute_reply":"2024-11-12T01:29:07.864164Z","shell.execute_reply.started":"2024-11-12T01:29:07.859669Z"},"trusted":true},"outputs":[],"source":["from pyspark.ml.classification import DecisionTreeClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.feature import VectorAssembler"]},{"cell_type":"markdown","metadata":{},"source":["### Jalankan Algo"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:29:08.588144Z","iopub.status.busy":"2024-11-12T01:29:08.587690Z","iopub.status.idle":"2024-11-12T01:32:48.196056Z","shell.execute_reply":"2024-11-12T01:32:48.194915Z","shell.execute_reply.started":"2024-11-12T01:29:08.588105Z"},"trusted":true},"outputs":[],"source":["dt_classifier = DecisionTreeClassifier(labelCol='label', featuresCol='final_features')\n","\n","dt_model = dt_classifier.fit(train_data)\n","\n","predictions = dt_model.transform(test_data)\n","\n","predictions.select('label', 'prediction', 'probability').show(10)\n","\n","evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n","accuracy = evaluator.evaluate(predictions)\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n","\n","f1_evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='f1')\n","f1_score = f1_evaluator.evaluate(predictions)\n","print(f\"F1-Score: {f1_score:.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Visualisasi Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:32:48.199633Z","iopub.status.busy":"2024-11-12T01:32:48.198075Z","iopub.status.idle":"2024-11-12T01:33:07.588089Z","shell.execute_reply":"2024-11-12T01:33:07.586919Z","shell.execute_reply.started":"2024-11-12T01:32:48.199581Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","# Mengambil prediksi dan label sebenarnya dari PySpark ke Pandas\n","predictions_pd = predictions.select('label', 'prediction').toPandas()\n","\n","# Membuat confusion matrix\n","cm = confusion_matrix(predictions_pd['label'], predictions_pd['prediction'])\n","\n","# Visualisasi confusion matrix\n","plt.figure(figsize=(8,6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Prediksi')\n","plt.ylabel('Label Sebenarnya')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Visualisasi ROC Curve and AUC"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:33:07.589825Z","iopub.status.busy":"2024-11-12T01:33:07.589477Z","iopub.status.idle":"2024-11-12T01:33:28.694742Z","shell.execute_reply":"2024-11-12T01:33:28.693626Z","shell.execute_reply.started":"2024-11-12T01:33:07.589791Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","\n","# Mengambil probabilitas prediksi dari PySpark ke Pandas\n","y_true = predictions_pd['label']\n","y_scores = predictions.select('probability').toPandas()['probability'].apply(lambda x: x[1])\n","\n","# Menghitung ROC Curve dan AUC\n","fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","roc_auc = auc(fpr, tpr)\n","\n","# Visualisasi ROC Curve\n","plt.figure(figsize=(8,6))\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Simpan Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-11-12T01:28:01.123053Z","iopub.status.idle":"2024-11-12T01:28:01.124205Z","shell.execute_reply":"2024-11-12T01:28:01.123884Z","shell.execute_reply.started":"2024-11-12T01:28:01.123852Z"},"trusted":true},"outputs":[],"source":["dt_model_path = \"/kaggle/working/decision_tree_model\"\n","dt_model.save(dt_model_path)\n","\n","print(f\"Decision Tree model saved at {dt_model_path}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Gradient Boosted Tree"]},{"cell_type":"markdown","metadata":{},"source":["### Import Modul"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:33:28.698133Z","iopub.status.busy":"2024-11-12T01:33:28.697689Z","iopub.status.idle":"2024-11-12T01:33:28.704419Z","shell.execute_reply":"2024-11-12T01:33:28.703178Z","shell.execute_reply.started":"2024-11-12T01:33:28.698086Z"},"trusted":true},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.classification import GBTClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator"]},{"cell_type":"markdown","metadata":{},"source":["### Jalankan Algo"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:33:28.705928Z","iopub.status.busy":"2024-11-12T01:33:28.705594Z","iopub.status.idle":"2024-11-12T01:46:00.519859Z","shell.execute_reply":"2024-11-12T01:46:00.518283Z","shell.execute_reply.started":"2024-11-12T01:33:28.705894Z"},"trusted":true},"outputs":[],"source":["gbt_classifier = GBTClassifier(labelCol='label', featuresCol='final_features', maxIter=10)\n","\n","gbt_model = gbt_classifier.fit(train_data)\n","\n","predictions = gbt_model.transform(test_data)\n","\n","predictions.select('label', 'prediction', 'probability').show(10)\n","\n","evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n","accuracy = evaluator.evaluate(predictions)\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n","\n","f1_evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='f1')\n","f1_score = f1_evaluator.evaluate(predictions)\n","print(f\"F1-Score: {f1_score:.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Visualisasi Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:46:00.522209Z","iopub.status.busy":"2024-11-12T01:46:00.521788Z","iopub.status.idle":"2024-11-12T01:46:18.628656Z","shell.execute_reply":"2024-11-12T01:46:18.627412Z","shell.execute_reply.started":"2024-11-12T01:46:00.522167Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","# Mengambil prediksi dan label sebenarnya dari PySpark ke Pandas\n","predictions_pd = predictions.select('label', 'prediction').toPandas()\n","\n","# Membuat confusion matrix\n","cm = confusion_matrix(predictions_pd['label'], predictions_pd['prediction'])\n","\n","# Visualisasi confusion matrix\n","plt.figure(figsize=(8,6))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Prediksi')\n","plt.ylabel('Label Sebenarnya')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Visualisasi ROC Curve and AUC"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T01:46:18.630785Z","iopub.status.busy":"2024-11-12T01:46:18.630319Z","iopub.status.idle":"2024-11-12T01:46:38.870227Z","shell.execute_reply":"2024-11-12T01:46:38.868867Z","shell.execute_reply.started":"2024-11-12T01:46:18.630736Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","\n","# Mengambil probabilitas prediksi dari PySpark ke Pandas\n","y_true = predictions_pd['label']\n","y_scores = predictions.select('probability').toPandas()['probability'].apply(lambda x: x[1])\n","\n","# Menghitung ROC Curve dan AUC\n","fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n","roc_auc = auc(fpr, tpr)\n","\n","# Visualisasi ROC Curve\n","plt.figure(figsize=(8,6))\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve')\n","plt.legend(loc=\"lower right\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Simpan Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-11-12T01:28:01.135103Z","iopub.status.idle":"2024-11-12T01:28:01.135521Z","shell.execute_reply":"2024-11-12T01:28:01.135325Z","shell.execute_reply.started":"2024-11-12T01:28:01.135304Z"},"trusted":true},"outputs":[],"source":["gbt_model_path = \"/kaggle/working/gbt_model\"\n","gbt_model.save(gbt_model_path)\n","\n","print(f\"GBT model saved at {gbt_model_path}\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5676126,"sourceId":9361420,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
